
* Day-1

http://ml4a.github.io/

http://ml4a.github.io/classes/itp-S16/

https://soma-na.slack.com/messages/general/

kogan.gene@gmail.com

Week 1: convolutional neural networks
Week 2: wekinator + applications
Week 3: applications of deep neural nets
Week 4: special topics + make-believe

Samim Winiger, Memo Akten

Meapsoft

classification, regression, clustering

supervised vs. unsupervised

Edsger Diikstra

t-SNE: take high-dimensional data and compact to two dimensions and visualize them. (using convolutional networks)

Some examples:
Jason Levine, Hannah Davis, Mike Tyka
Terrapattern, Doppelcam http://doppel.camera/
Neural net generated fonts - Erik Bernhardsson
LSTM sci-fi assistant - Robin Sloan
RNN draws fake Kanji
https://medium.com/@samim/ted-rnn-machine-generated-ted-talks-3dd682b894c0#.rpqvq3fyb

Trolley problem



* Day-2

Nowness - Sol Lewitt https://vimeo.com/157735423

Neural networks:
brainbow
perceptron

sum of input x weights --> activation function(e.g. sigmoid, ReLu)
ReLu (Rectified Linear Unit): if it's negative, make it 0 (very common in neural networks)

forward pass: http://ml4a.github.io/dev/demos/demo_forwardpass.html
hidden layers
MNIST: classifying hand-written digit database

When we have random weights, the system will have random behavior
The process of training is an algorithm that adjusts the weights
Compare the result with the original and adjust the weights

Neural networks map one "volume" of information to another

Simple uses:
prediction, categorization
compressing low-value information to high-value (unsupervised)
mapping events, actions in media art
encoding, decoding
generative

supervised: we have a desired output and teach the program to generate that output

CIFAR-10 database: basic objects
